{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "_BATCH_NORM_DECAY = 0.9\n",
    "_BATCH_NORM_EPSILON = 1e-05\n",
    "_LEAKY_RELU = 0.1\n",
    "_ANCHORS = [(10, 13), (16, 30), (33, 23),\n",
    "            (30, 61), (62, 45), (59, 119),\n",
    "            (116, 90), (156, 198), (373, 326)]\n",
    "_MODEL_SIZE = (416, 416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(inputs, training, data_format):\n",
    "    return tf.layers.batch_normalization(\n",
    "        inputs=inputs, axis=1 if data_format == 'channels_first' else 3,\n",
    "        momentum=_BATCH_NORM_DECAY, epsilon=_BATCH_NORM_EPSILON,\n",
    "        scale=True, training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_padding(inputs, kernel_size, data_format):\n",
    "    print('[INFO] fixed padding')\n",
    "    pad_total = kernel_size - 1\n",
    "    pad_beg = pad_total // 2\n",
    "    pad_end = pad_total - pad_beg\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [0, 0],\n",
    "                                        [pad_beg, pad_end],\n",
    "                                        [pad_beg, pad_end]])\n",
    "    else:\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
    "                                        [pad_beg, pad_end], [0, 0]])\n",
    "    return padded_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_fixed_padding(inputs, filters, kernel_size, data_format, strides=1):\n",
    "    if strides > 1:\n",
    "        inputs = fixed_padding(inputs, kernel_size, data_format)\n",
    "\n",
    "    return tf.layers.conv2d(\n",
    "        inputs=inputs, filters=filters, kernel_size=kernel_size,\n",
    "        strides=strides, padding=('SAME' if strides == 1 else 'VALID'),\n",
    "        use_bias=False, data_format=data_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53_residual_block(inputs, filters, training, data_format,\n",
    "                             strides=1):\n",
    "    shortcut = inputs\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters=filters, kernel_size=1, strides=strides,\n",
    "        data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(\n",
    "        inputs, filters=2 * filters, kernel_size=3, strides=strides,\n",
    "        data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs += shortcut\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53(inputs, training, data_format):\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=32, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    print(inputs.get_shape())\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=64, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    print(inputs.get_shape())\n",
    "    inputs = darknet53_residual_block(inputs, filters=32, training=training,\n",
    "                                      data_format=data_format)\n",
    "    print(inputs.get_shape())\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=128, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    print(inputs.get_shape())\n",
    "    for _ in range(2):\n",
    "        inputs = darknet53_residual_block(inputs, filters=64,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "    print(inputs.get_shape())\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=256, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    print(inputs.get_shape())\n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(inputs, filters=128,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "\n",
    "    print(inputs.get_shape())\n",
    "    route1 = inputs\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=512, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    print(inputs.get_shape())\n",
    "    for _ in range(8):\n",
    "        inputs = darknet53_residual_block(inputs, filters=256,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "\n",
    "    route2 = inputs\n",
    "    print(inputs.get_shape())\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=1024, kernel_size=3,\n",
    "                                  strides=2, data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "    print(inputs.get_shape())\n",
    "    for _ in range(4):\n",
    "        inputs = darknet53_residual_block(inputs, filters=512,\n",
    "                                          training=training,\n",
    "                                          data_format=data_format)\n",
    "    print(inputs.get_shape())\n",
    "    return route1, route2, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_convolution_block(inputs, filters, training, data_format):\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=filters, kernel_size=1,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    route = inputs\n",
    "\n",
    "    inputs = conv2d_fixed_padding(inputs, filters=2 * filters, kernel_size=3,\n",
    "                                  data_format=data_format)\n",
    "    inputs = batch_norm(inputs, training=training, data_format=data_format)\n",
    "    inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "\n",
    "    return route, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_layer(inputs, n_classes, anchors, img_size, data_format):\n",
    "    \"\"\"Creates Yolo final detection layer.\n",
    "\n",
    "    Detects boxes with respect to anchors.\n",
    "\n",
    "    Args:\n",
    "        inputs: Tensor input.\n",
    "        n_classes: Number of labels.\n",
    "        anchors: A list of anchor sizes.\n",
    "        img_size: The input size of the model.\n",
    "        data_format: The input format.\n",
    "\n",
    "    Returns:\n",
    "        Tensor output.\n",
    "    \"\"\"\n",
    "    n_anchors = len(anchors)\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    print(\"input : \",shape)\n",
    "    # 나오는 값의 크기 : n_anchors * (5 + n_classes)\n",
    "    inputs = tf.layers.conv2d(inputs, filters=n_anchors * (5 + n_classes),\n",
    "                              kernel_size=1, strides=1, use_bias=True,\n",
    "                              data_format=data_format)\n",
    "    shape = inputs.get_shape().as_list()\n",
    "    print(\"n_anchors * (5 + n_classes) : \",shape)\n",
    "    grid_shape = shape[2:4] if data_format == 'channels_first' else shape[1:3]\n",
    "    print(\"grid : \",grid_shape)\n",
    "    if data_format == 'channels_first':\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "    inputs = tf.reshape(inputs, [-1, n_anchors * grid_shape[0] * grid_shape[1],\n",
    "                                 5 + n_classes])\n",
    "    print(\"reshape : \",inputs.get_shape().as_list())\n",
    "    strides = (img_size[0] // grid_shape[0], img_size[1] // grid_shape[1])\n",
    "    print(\"output strides\",strides)\n",
    "    box_centers, box_shapes, confidence, classes = \\\n",
    "        tf.split(inputs, [2, 2, 1, n_classes], axis=-1)\n",
    "    print('box center : ',box_centers.get_shape().as_list())\n",
    "    print('box shape : ',box_shapes.get_shape().as_list())\n",
    "    print('box confidence : ',confidence.get_shape().as_list())\n",
    "    print('box classes : ',classes.get_shape().as_list())\n",
    "    x = tf.range(grid_shape[0], dtype=tf.float32)\n",
    "    print('grid x : ',x.get_shape().as_list())\n",
    "    y = tf.range(grid_shape[1], dtype=tf.float32)\n",
    "    print('grid y : ',y.get_shape().as_list())\n",
    "    x_offset, y_offset = tf.meshgrid(x, y)\n",
    "    x_offset = tf.reshape(x_offset, (-1, 1))\n",
    "    y_offset = tf.reshape(y_offset, (-1, 1))\n",
    "    x_y_offset = tf.concat([x_offset, y_offset], axis=-1)\n",
    "    x_y_offset = tf.tile(x_y_offset, [1, n_anchors])\n",
    "    x_y_offset = tf.reshape(x_y_offset, [1, -1, 2])\n",
    "    print('grid offset : ',x_y_offset.get_shape().as_list())\n",
    "    box_centers = tf.nn.sigmoid(box_centers)\n",
    "    print('sigmoid box center : ',box_centers.get_shape().as_list())\n",
    "    box_centers = (box_centers + x_y_offset) * strides\n",
    "    print('offset + box center : ',box_centers.get_shape().as_list())\n",
    "    anchors = tf.tile(anchors, [grid_shape[0] * grid_shape[1], 1])\n",
    "    print('anchors',anchors.get_shape().as_list())\n",
    "    box_shapes = tf.exp(box_shapes) * tf.to_float(anchors)\n",
    "    with tf.Session() as sess:\n",
    "        print(sess.run(anchors))\n",
    "    print('box shape : ',box_shapes.get_shape().as_list())\n",
    "    confidence = tf.nn.sigmoid(confidence)\n",
    "    print('box confidence : ',confidence.get_shape().as_list())\n",
    "    classes = tf.nn.sigmoid(classes)\n",
    "    print('box classes : ',classes.get_shape().as_list())\n",
    "    inputs = tf.concat([box_centers, box_shapes,\n",
    "                        confidence, classes], axis=-1)\n",
    "    print('result : ',inputs.get_shape().as_list())\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(inputs, out_shape, data_format):\n",
    "    if data_format == 'channels_first':\n",
    "        inputs = tf.transpose(inputs, [0, 2, 3, 1])\n",
    "        new_height = out_shape[3]\n",
    "        new_width = out_shape[2]\n",
    "    else:\n",
    "        new_height = out_shape[2]\n",
    "        new_width = out_shape[1]\n",
    "\n",
    "    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width))\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_preprocessing(gt_boxes,input_shape,anchors, num_classes):\n",
    "    '''\n",
    "    gt_boxes : true box, shape = (m,T,5)\n",
    "        x_min, y_min, x_max, y_max, class_id\n",
    "    anchors : shape = (N,2) \n",
    "        width,height\n",
    "    '''\n",
    "    \n",
    "    num_layers = len(anchors)//3\n",
    "    anchor_mask = [[6,7,8],[3,4,5],[0,1,2]] if num_layers==3 else [[3,4,5],[1,2,3]]\n",
    "    \n",
    "    gt_boxes = np.array(gt_boxes, dtype='float32')\n",
    "    input_shape = np.array(input_shape, dtype='int32')\n",
    "    \n",
    "    boxes_xy = (gt_boxes[...,0:2] + gt_boxes[...,2:4]) // 2\n",
    "    boxes_wh = gt_boxes[...,2:4] - gt_boxes[...,0:2]\n",
    "    \n",
    "    gt_boxes[..., 0:2] = boxes_xy/input_shape[::-1] # 1x1\n",
    "    gt_boxes[..., 2:4] = boxes_wh/input_shape[::-1] # 1x1\n",
    "    \n",
    "    m = gt_boxes.shape[0]\n",
    "    \n",
    "    grid_shapes = [input_shape//{0:32, 1:16, 2:8}[l] for l in range(num_layers)]\n",
    "    \n",
    "    y_true = [np.zeros((m,grid_shapes[l][0],grid_shapes[l][1],len(anchor_mask[l]),5+num_classes),\n",
    "        dtype='float32') for l in range(num_layers)]\n",
    "    \n",
    "    print(y_true[0].shape) # (batch, grid , grid , anchor , [x,y,w,h,c])\n",
    "    \n",
    "    anchors = np.expand_dims(anchors, 0)\n",
    "    anchor_maxes = anchors / 2.\n",
    "    anchor_mins = -anchor_maxes\n",
    "    valid_mask = boxes_wh[..., 0]>0 # 유효성 검사 w > 0\n",
    "    \n",
    "    # 최적의 anchor를 찾고 그 anchor를 이용해 실제 y를 (batch, grid, grid , anchor , 85)(grid = 13,26,52)의 형태로 만든다.\n",
    "    for b in range(m):\n",
    "        wh = boxes_wh[b, valid_mask[b]] # (batch,num_valid_boxes,2)\n",
    "        if len(wh)==0: \n",
    "            continue\n",
    "        \n",
    "        wh = np.expand_dims(wh, -2) # (batch,num_valid_boxes,1,2)\n",
    "        box_maxes = wh / 2.\n",
    "        box_mins = -box_maxes\n",
    "        \n",
    "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
    "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
    "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "        intersect_area = intersect_wh[...,0] + intersect_wh[...,1]\n",
    "        box_area = wh[..., 0] * wh[..., 1]\n",
    "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
    "        # Find best anchor for each true box\n",
    "        \n",
    "        print(iou.shape)\n",
    "        \n",
    "        best_anchor = np.argmax(iou, axis=-1)\n",
    "        \n",
    "        print(best_anchor.shape)\n",
    "        \n",
    "        count = 0\n",
    "        for t, n in enumerate(best_anchor):\n",
    "            for l in range(num_layers):\n",
    "                if n in anchor_mask[l]:\n",
    "                    i = np.floor(gt_boxes[b,t,0]*grid_shapes[l][1]).astype('int32')\n",
    "                    j = np.floor(gt_boxes[b,t,1]*grid_shapes[l][0]).astype('int32')\n",
    "                    k = anchor_mask[l].index(n)\n",
    "                    c = gt_boxes[b,t, 4].astype('int32')\n",
    "                    y_true[l][b, j, i, k, 0:4] = gt_boxes[b,t, 0:4]\n",
    "                    y_true[l][b, j, i, k, 4] = 1\n",
    "                    y_true[l][b, j, i, k, 5+c] = 1\n",
    "\n",
    "#[batch_size,layers,feat_size,feat_size,num_of_anchors each layer,c+5]\n",
    "    return y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 13, 13, 3, 85)\n",
      "(3, 9)\n",
      "(3,)\n",
      "(6, 9)\n",
      "(6,)\n",
      "(2, 13, 13, 3, 85)\n"
     ]
    }
   ],
   "source": [
    "gt = np.random.rand(2,10,5)\n",
    "\n",
    "y_true = box_preprocessing(gt,_MODEL_SIZE,_ANCHORS,80)\n",
    "print(y_true[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(pre_boxes, true_boxes):\n",
    "    pred_xy = pre_boxes[..., :2]\n",
    "    pred_wh = pre_boxes[..., 2:4]\n",
    "    true_xy = true_boxes[..., :2]\n",
    "    true_wh = true_boxes[..., 2:4]\n",
    "\n",
    "    pred_wh_half = pred_wh / 2.\n",
    "    pred_mins = pred_xy - pred_wh_half\n",
    "    pred_maxes = pred_xy + pred_wh_half\n",
    "\n",
    "    true_wh_half = true_wh / 2.\n",
    "    true_mins = true_xy - true_wh_half\n",
    "    true_maxes = true_xy + true_wh_half\n",
    "\n",
    "    intersect_mins = tf.maximum(pred_mins, true_mins)\n",
    "    intersect_maxes = tf.minimum(pred_maxes, true_maxes)\n",
    "\n",
    "    intersect_wh = tf.maximum(intersect_maxes - intersect_mins, 0.)\n",
    "    intersect_areas = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "    true_areas = true_wh[..., 0] * true_wh[..., 1]\n",
    "    pred_areas = pred_wh[..., 0] * pred_wh[..., 1]\n",
    "\n",
    "    union_areas = pred_areas + true_areas - intersect_areas\n",
    "    iou_score = tf.truediv(intersect_areas, union_areas)\n",
    "\n",
    "    return iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolov3_loss(y_pred, y_true, anchors, input_shape):\n",
    "    \n",
    "    '''\n",
    "    detect1 = (batch, 13 , 13 , 3, 85)\n",
    "    detect2 = (batch, 26 , 26 , 3, 85)\n",
    "    detect3 = (batch, 52 , 52 , 3, 85)\n",
    "    '''\n",
    "    \n",
    "    # expanding\n",
    "    anchors = tf.constant(anchors, dtype='float', shape=[1, 1, 1, 9, 2])\n",
    "    sess = tf.Session()\n",
    "    print('anchors : ',sess.run(anchors))\n",
    "    \n",
    "    C = 80\n",
    "    ignore_thresh = 0.5\n",
    "    batch_size = 1\n",
    "    \n",
    "    cellbase_x = tf.to_float(tf.reshape(tf.tile(tf.range(52), [52]), (1, 52, 52, 1, 1)))\n",
    "    print(sess.run(cellbase_x).shape)\n",
    "    cellbase_y = tf.transpose(cellbase_x, (0, 2, 1, 3, 4))\n",
    "    print(sess.run(cellbase_y).shape)\n",
    "    cellbase_grid = tf.tile(tf.concat([cellbase_x, cellbase_y], -1), [batch_size, 1, 1, 3, 1])\n",
    "    print(sess.run(cellbase_grid).shape)\n",
    "    \n",
    "    img_w = input_shape[0]\n",
    "    img_h = input_shape[1]\n",
    "    img_factor = tf.reshape(tf.cast([img_w, img_h], tf.float32), [1, 1, 1, 1, 2])\n",
    "    print('shape : ',sess.run(img_factor))\n",
    "    \n",
    "    loss = 0\n",
    "    sum_loss_xy = 0\n",
    "    sum_loss_wh = 0\n",
    "    sum_loss_c = 0\n",
    "    sum_loss_class = 0\n",
    "    \n",
    "    for i in range(1):\n",
    "        anchor = anchors[..., 3 * i:3 * (i + 1), :]\n",
    "        print('anchor : ',sess.run(anchor))\n",
    "        object_mask = y_true[i][...,4:5]\n",
    "        \n",
    "        grid_w = tf.shape(y_pred[i])[1]  # 13\n",
    "        grid_h = tf.shape(y_pred[i])[2]  # 13\n",
    "        grid_factor = tf.reshape(tf.cast([grid_w, grid_h], tf.float32), [1, 1, 1, 1, 2])\n",
    "        print('grid_factor : ',sess.run(grid_factor))\n",
    "        \n",
    "        # 예측한 box를 새롭게 조절된 box로 만든다.\n",
    "        net_out_reshape = tf.reshape(y_pred[i], [-1, grid_w, grid_h, 3, (4 + 1 + C)])\n",
    "        adjusted_out_xy = (cellbase_grid[:, :grid_w, :grid_h, :, :] + tf.sigmoid(\n",
    "            net_out_reshape[..., :2])) / grid_factor\n",
    "        adjusted_out_wh = tf.exp(net_out_reshape[..., 2:4]) * anchor / img_factor\n",
    "        adjusted_out_c = tf.expand_dims(tf.sigmoid(net_out_reshape[..., 4]), axis=-1)\n",
    "        adjusted_out_class = tf.sigmoid(net_out_reshape[..., 5:])\n",
    "        adjusted_net_out = tf.concat([adjusted_out_xy, adjusted_out_wh, adjusted_out_c, adjusted_out_class],axis=-1)\n",
    "        \n",
    "        pred_boxes = tf.expand_dims(adjusted_net_out[..., 0:4], 4)\n",
    "        \n",
    "        # 실제 box를 새롭게 조절된 box로 만든다.\n",
    "        adjusted_true_xy = y_true[i][..., :2] * grid_factor - cellbase_grid[:, :grid_w, :grid_h, :, :]\n",
    "        adjusted_true_wh = tf.log(y_true[i][..., 2:4] / anchor * img_factor + 1e-9)  # 1e-9 just avoid log(0) = -inf\n",
    "\n",
    "        adjusted_true_c = y_true[i][..., 4:5]\n",
    "        adjusted_true_class = y_true[i][..., 5:]\n",
    "        \n",
    "        # TODO i don't like for loop\n",
    "        \n",
    "        ignore_masks = list()\n",
    "        for k in range(batch_size):\n",
    "            origin_box = tf.boolean_mask(y_true[i][k, ..., :4], tf.cast(y_true[i][k, ..., 4], dtype=bool))\n",
    "            origin_box = tf.tile(tf.reshape(origin_box, shape=[1, 1, 1, -1, 4]), [grid_w, grid_h, 3, 1, 1])\n",
    "            iou_scores = iou(pred_boxes[k], origin_box)\n",
    "            best_ious = tf.reduce_max(iou_scores, axis=-1)\n",
    "            ignore_mask = tf.expand_dims(tf.to_float(best_ious < ignore_thresh), -1)\n",
    "            ignore_masks.append(ignore_mask)\n",
    "        ignore_masks = tf.stack(ignore_masks)\n",
    "        xywh_scale = 2 - y_true[i][..., 2:3] * y_true[i][..., 3:4]\n",
    "        \n",
    "        loss_xy = tf.reduce_sum(\n",
    "            object_mask * xywh_scale * tf.nn.sigmoid_cross_entropy_with_logits(logits=net_out_reshape[..., :2],\n",
    "                                                                               labels=adjusted_true_xy)) / batch_size\n",
    "        loss_wh = tf.reduce_sum(\n",
    "            object_mask * xywh_scale * 0.5 * tf.square(net_out_reshape[..., 2:4] - adjusted_true_wh)) / batch_size\n",
    "        \n",
    "        loss_c = tf.reduce_sum(\n",
    "            object_mask * tf.nn.sigmoid_cross_entropy_with_logits(logits=net_out_reshape[..., 4:5],\n",
    "                                                                  labels=adjusted_true_c) + (\n",
    "                    1 - object_mask) * tf.nn.sigmoid_cross_entropy_with_logits(logits=net_out_reshape[..., 4:5],\n",
    "                                                                               labels=adjusted_true_c) * ignore_masks) / batch_size\n",
    "        loss_class = tf.reduce_sum(\n",
    "            object_mask * tf.nn.sigmoid_cross_entropy_with_logits(logits=net_out_reshape[..., 5:],\n",
    "                                                                  labels=adjusted_true_class)) / batch_size\n",
    "\n",
    "        sum_loss_xy += loss_xy\n",
    "        sum_loss_wh += loss_wh\n",
    "        sum_loss_c += loss_c\n",
    "        sum_loss_class += loss_class\n",
    "        loss += loss_xy + loss_wh + loss_c + loss_class\n",
    "\n",
    "    tf.summary.scalar('loss', loss)\n",
    "    tf.summary.scalar('loss_xy', sum_loss_xy)\n",
    "    tf.summary.scalar('loss_wh', sum_loss_wh)\n",
    "    tf.summary.scalar('loss_c', sum_loss_c)\n",
    "    tf.summary.scalar('loss_class', sum_loss_class)\n",
    "    \n",
    "    sess.close()\n",
    "    \n",
    "    return loss,sum_loss_xy,sum_loss_wh,sum_loss_c,sum_loss_class\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anchors :  [[[[[ 10.  13.]\n",
      "    [ 16.  30.]\n",
      "    [ 33.  23.]\n",
      "    [ 30.  61.]\n",
      "    [ 62.  45.]\n",
      "    [ 59. 119.]\n",
      "    [116.  90.]\n",
      "    [156. 198.]\n",
      "    [373. 326.]]]]]\n",
      "(1, 52, 52, 1, 1)\n",
      "(1, 52, 52, 1, 1)\n",
      "(1, 52, 52, 3, 2)\n",
      "shape :  [[[[[416. 416.]]]]]\n",
      "anchor :  [[[[[10. 13.]\n",
      "    [16. 30.]\n",
      "    [33. 23.]]]]]\n",
      "grid_factor :  [[[[[13. 13.]]]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'add_124:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'add_117:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'add_118:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'add_119:0' shape=() dtype=float32>,\n",
       " <tf.Tensor 'add_120:0' shape=() dtype=float32>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolov3_loss(y_true,y_true,_ANCHORS,_MODEL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-900522f3e1d7>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-17-900522f3e1d7>\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    true_detect3 = tf.placeholder(tf.float32, [None, 52 , 52 . 3, 42])\u001b[0m\n\u001b[1;37m                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "num_anchors = len(anchors)//3\n",
    "\n",
    "inputs = tf.placeholder(tf.float32, [None, 416, 416, 3],name='inputs')\n",
    "true_detect1 = tf.placeholder(tf.float32, [None, 13 , 13 , 3, 42])\n",
    "true_detect2 = tf.placeholder(tf.float32, [None, 26 , 26 , 3, 42])\n",
    "true_detect3 = tf.placeholder(tf.float32, [None, 52 , 52 , 3, 42])\n",
    "is_training = tf.placeholder(tf.bool,name='training')\n",
    "# layer = inputs \n",
    "\n",
    "'''\n",
    "route1 = (batch , 13 , 13 , 256)\n",
    "route2 = (batch , 26 , 26 , 512)\n",
    "inputs = (batch , 13 , 13 , 1024)\n",
    "'''\n",
    "\n",
    "route1, route2, inputs = darknet53(inputs, training=training,\n",
    "                                               data_format=self.data_format)\n",
    "\n",
    "route, inputs = yolo_convolution_block(\n",
    "                inputs, filters=512, training=training,\n",
    "                data_format=self.data_format)\n",
    "# detection\n",
    "target_detect1 = yolo_layer(inputs, n_classes=self.n_classes,\n",
    "                     anchors=_ANCHORS[6:9],\n",
    "                     img_size=self.model_size,\n",
    "                     data_format=self.data_format)\n",
    "\n",
    "inputs = conv2d_fixed_padding(route, filters=256, kernel_size=1,\n",
    "                              data_format=self.data_format)\n",
    "inputs = batch_norm(inputs, training=training,\n",
    "                    data_format=self.data_format)\n",
    "inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "upsample_size = route2.get_shape().as_list()\n",
    "inputs = upsample(inputs, out_shape=upsample_size,\n",
    "                  data_format=self.data_format)\n",
    "axis = 1 if self.data_format == 'channels_first' else 3\n",
    "inputs = tf.concat([inputs, route2], axis=axis)\n",
    "\n",
    "route, inputs = yolo_convolution_block(\n",
    "    inputs, filters=256, training=training,\n",
    "    data_format=self.data_format)\n",
    "target_detect2 = yolo_layer(inputs, n_classes=self.n_classes,\n",
    "                     anchors=_ANCHORS[3:6],\n",
    "                     img_size=self.model_size,\n",
    "                     data_format=self.data_format)\n",
    "\n",
    "inputs = conv2d_fixed_padding(route, filters=128, kernel_size=1,\n",
    "                              data_format=self.data_format)\n",
    "inputs = batch_norm(inputs, training=training,\n",
    "                    data_format=self.data_format)\n",
    "inputs = tf.nn.leaky_relu(inputs, alpha=_LEAKY_RELU)\n",
    "upsample_size = route1.get_shape().as_list()\n",
    "inputs = upsample(inputs, out_shape=upsample_size,\n",
    "                  data_format=self.data_format)\n",
    "inputs = tf.concat([inputs, route1], axis=axis)\n",
    "route, inputs = yolo_convolution_block(\n",
    "    inputs, filters=128, training=training,\n",
    "    data_format=self.data_format)\n",
    "target_detect3 = yolo_layer(inputs, n_classes=self.n_classes,\n",
    "                     anchors=_ANCHORS[0:3],\n",
    "                     img_size=self.model_size,\n",
    "                     data_format=self.data_format)\n",
    "\n",
    "#target = tf.concat([target_detect1, target_detect2, target_detect3], axis=1)\n",
    "\n",
    "target_detect1 = tf.reshape(target_detect1,(-1,13,13,3,85))\n",
    "target_detect2 = tf.reshape(target_detect2,(-1,26,26,3,85))\n",
    "target_detect3 = tf.reshape(target_detect3,(-1,52,52,3,85))\n",
    "\n",
    "y_pred = [target_detect1,target_detect2,target_detect3]\n",
    "y_true = [true_detect1,true_detect2,true_detect3]\n",
    "\n",
    "\n",
    "learning_rate = 0.0001\n",
    "\n",
    "loss,loss_xy,loss_wh,loss_c,loss_class = yolo3_loss(y_pred, y_true,_ANCHORS)\n",
    "\n",
    "\n",
    "'''\n",
    "---------------------------------------------------------- \n",
    "여기 까지 완료\n",
    "아래는 학습\n",
    "----------------------------------------------------------\n",
    "'''\n",
    "\n",
    "update_opts = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies([tf.group(*update_opts)]):\n",
    "    train_opt = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "with tf.Session() as sess:\n",
    "    train_writer = tf.summary.FileWriter(FLAGS.log_dir,sess.graph)\n",
    "    saver = tf.train.Saver(max_to_keep=5)\n",
    "    img_path, annotation = get_path_and_annotation('./data/train_ocr.txt')\n",
    "    train_feeder = read_data(img_path,annotation,FLAGS.batch_size,False)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    ckpt = tf.train.latest_checkpoint(FLAGS.checkpoint_dir)\n",
    "    if ckpt:\n",
    "        saver.restore(sess,ckpt)\n",
    "        print('Restore from the checkpoint {0}'.format(ckpt))\n",
    "    else:\n",
    "        print('Train yolo from start')\n",
    "    for i in range(50000):\n",
    "        image_batch, annotation_batch = next(train_feeder)\n",
    "        image_batch, annotation_batch = resize_images_boxes(image_batch,annotation_batch,15)\n",
    "        y_true = preprocess_true_boxes(annotation_batch, (FLAGS.image_size,FLAGS.image_size), anchors, FLAGS.num_classes)\n",
    "        [_,total_loss,current_lossxy,current_losswh,current_lossc,current_loss_class,temp_pred] = sess.run([train_opt,loss,loss_xy,loss_wh,loss_c,loss_class,y_pred],feed_dict={inputs:image_batch,y_true_1:y_true[0],y_true_2:y_true[1],y_true_3:y_true[2],is_training: True})\n",
    "        if(i%500 == 0):\n",
    "            saver.save(sess,os.path.join(FLAGS.checkpoint_dir,'OCR-'),global_step=i)\n",
    "            print('Model saved!!')\n",
    "            \n",
    "            #######################################################################\n",
    "            constant_graph = convert_variables_to_constants(sess, sess.graph_def, ['boxes','scores','classes'])\n",
    "            with tf.gfile.FastGFile('./model.pb', mode='wb') as f:\n",
    "                f.write(constant_graph.SerializeToString())\n",
    "            ######################################################################\n",
    "            \n",
    "            \n",
    "            \n",
    "        print('Batch: '+str(i)+'   Current total loss: '+str(total_loss)+'  loss_xy: '+str(current_lossxy)+'  loss_wh: '+str(current_losswh)+'  loss_c: '+str(current_lossc)+' loss_class: '+str(current_loss_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(img_list,annotation,batch_size,aug):\n",
    "    num_batch = len(img_list)/batch_size\n",
    "    count=0\n",
    "    while(True):\n",
    "        image_data = []\n",
    "        annotation_data = []\n",
    "        for i in range(batch_size):\n",
    "            temp_index = i+count*batch_size\n",
    "            temp_index %=len(img_list) \n",
    "            image = cv2.imread(img_list[temp_index])\n",
    "            if aug:\n",
    "                image = data_augmentation(image)\n",
    "            image = image[:,:,::-1]\n",
    "            image = image.astype(np.float32)\n",
    "            image_shape = image.shape\n",
    "#             image = cv2.resize(image,(FLAGS.image_size,FLAGS.image_size))\n",
    "            \n",
    "#             image = image/255\n",
    "            image_data.append(image)\n",
    "            annotation_data.append(np.array(annotation[temp_index]).astype(np.int32))\n",
    "        count+=1\n",
    "        image_data = np.array(image_data)\n",
    "        yield image_data,annotation_data\n",
    "\n",
    "def get_path_and_annotation(file_path):\n",
    "    annotation = []\n",
    "    img_path = []\n",
    "    line_list = []\n",
    "    with open(file_path,'r') as f:\n",
    "        for line in f:\n",
    "            temp=[]\n",
    "            line = line.strip('\\n')\n",
    "            line_list.append(line)\n",
    "        random.shuffle(line_list)\n",
    "\n",
    "    for i in line_list:\n",
    "        line = i.split(' ')\n",
    "        img_path.append(line[0])\n",
    "        temp = []\n",
    "        temp_inner= []\n",
    "        for j in range(1,len(line)):\n",
    "            temp.append(line[j].split(','))\n",
    "        annotation.append(temp)\n",
    "    return img_path,annotation\n",
    "\n",
    "def resize_images_boxes(image_batch,annotation_batch,max_num_box):\n",
    "    batch_size = image_batch.shape[0]\n",
    "    bbox = np.zeros((batch_size,max_num_box,5))\n",
    "#     target_size = FLAGS.image_size\n",
    "    image_size = (image_batch.shape[1],image_batch.shape[2])\n",
    "    x_ratio = FLAGS.image_size/image_size[1]\n",
    "    y_ratio = FLAGS.image_size/image_size[0]\n",
    "    temp_image = []\n",
    "    for i in range(batch_size):\n",
    "        temp_image.append(cv2.resize(image_batch[i],(FLAGS.image_size,FLAGS.image_size)))\n",
    "        for j in range(len(annotation_batch[i])):\n",
    "            bbox[i][j][0]= np.round(annotation_batch[i][j][0]*x_ratio)\n",
    "            bbox[i][j][1]= np.round(annotation_batch[i][j][1]*y_ratio)\n",
    "            bbox[i][j][2]= np.round(annotation_batch[i][j][2]*x_ratio)\n",
    "            bbox[i][j][3]= np.round(annotation_batch[i][j][3]*y_ratio)\n",
    "            bbox[i][j][4]= annotation_batch[i][j][4]\n",
    "    return np.array(temp_image,dtype=np.float32),bbox\n",
    "\n",
    "def data_augmentation(img,annotation):\n",
    "    for anno in annotation:\n",
    "        coords = []\n",
    "        xywh_t = []\n",
    "        for i in anno[...,0:4]:\n",
    "            coords.append(tl.prepro.obj_box_coord_upleft_butright_to_centroid(i))\n",
    "        im_flip, coords = tl.prepro.obj_box_left_right_flip(img,coords,is_rescale=False,is_center=True)\n",
    "        for i in range(len(coords)):\n",
    "            xywh_t.append(tl.prepro.obj_box_coord_centroid_to_upleft_butright(coords[i]))\n",
    "    return xywh_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
